{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4a99a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import math\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "367627ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206317\n",
      "51579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "206317"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FeatureDataset(Dataset):\n",
    "    def __init__(self, file_name):\n",
    "        # read csv file and load row data into input and output\n",
    "        raw_data = pd.read_csv(file_name)\n",
    "        inputX = raw_data.iloc[0:len(raw_data), 0:15].values\n",
    "        outputY = raw_data.iloc[0:len(raw_data), 15].values\n",
    "        \n",
    "        #convert to torch tensors\n",
    "        self.data_X = torch.tensor(inputX,dtype=torch.float32,device=device)\n",
    "        self.data_Y = torch.tensor(outputY,device=device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_Y)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.data_X[idx], self.data_Y[idx]\n",
    "    \n",
    "dataSet = FeatureDataset(\"F:\\githubClone\\TCN\\m100_for_model.csv\")\n",
    "\n",
    "lenTrainingPercen = 80\n",
    "lenTestPercen = 20\n",
    "numTraining = math.ceil((len(dataSet)/100)*lenTrainingPercen)\n",
    "numTest = len(dataSet)-numTraining\n",
    "print(numTraining)\n",
    "print(numTest)\n",
    "train, val = torch.utils.data.random_split(dataSet, [numTraining, numTest])  # spilt the data to training set as well as test set\n",
    "len(train.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a08be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA = pd.read_csv(\"F:\\m100_for_model.csv\")\n",
    "# k = DATA.iloc[0:len(DATA),15]\n",
    "# k\n",
    "# DATA_pureInput = DATA.drop(['energy','aircraft'], axis = 1).values\n",
    "# Input_tensor = torch.tensor(DATA_pureInput)\n",
    "# DATA_output = DATA['energy'].values\n",
    "# Label_tensor = torch.tensor(DATA_output)\n",
    "# Label_tensor\n",
    "# x,y = torch.utils.data.random_split(range(10), [3, 7], generator=torch.Generator().manual_seed(42))\n",
    "# print(x.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a1a856a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048])\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = train,\n",
    "                                           batch_size = 2048, \n",
    "                                           shuffle = True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset = val, \n",
    "                                         batch_size = 10000,  # for batch size default is 1\n",
    "                                         shuffle = True) \n",
    "examples = enumerate(train_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)  # X = example_data, Y = example_targets\n",
    "print(example_targets.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cfb2fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ownMLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(ownMLP, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            #nn.Flatten(),\n",
    "            nn.Linear(input_dim,44), #1, # 1st para is input size after flatten, output is the number of neurons in hidden layers after input layer\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 2\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 3\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 4\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 5\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 6\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 7\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 8\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 9\n",
    "            nn.ReLU(inplace=True),   \n",
    "            nn.Linear(44,44), # 10\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 11\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 12\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 13\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 14\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 15\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 16\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 17\n",
    "            nn.ReLU(inplace=True),    \n",
    "            nn.Linear(44,44), # 18\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 19\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 20\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 21\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 22\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 23\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 24\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 25\n",
    "            nn.ReLU(inplace=True),   \n",
    "            nn.Linear(44,44), # 26\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 27\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 28\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 29\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 30\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 31\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 32\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,44), # 33\n",
    "            nn.ReLU(inplace=True),        \n",
    "            nn.Linear(44,44), # 34\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(44,output_dim), # 35\n",
    "            nn.ReLU(inplace=True),             \n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "model = ownMLP(15,1)\n",
    "model.to(device)\n",
    "criterion = nn.MSELoss()  # NOTE: MESLoss() is used for regression, while CrossEntroyLoss() is used for classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90587fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 1])\n",
      "0\n",
      "torch.Size([10000, 1])\n",
      "1\n",
      "torch.Size([10000, 1])\n",
      "2\n",
      "torch.Size([10000, 1])\n",
      "3\n",
      "torch.Size([10000, 1])\n",
      "4\n",
      "torch.Size([10000, 1])\n",
      "5\n",
      "torch.Size([4474, 1])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "mseList = []\n",
    "\n",
    "for epoch in range(1):\n",
    "    acc = 0\n",
    "    valid_acc = 0\n",
    "    for i, (inputData, outputData) in enumerate(train_loader):  # sweep through the entire training set\n",
    "        outputData = outputData.unsqueeze(1)\n",
    "        model.train()\n",
    "        inData = inputData.to(device)\n",
    "        outData = outputData.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(inData)\n",
    "        loss = criterion(outputs, outData.float())\n",
    "        # Backward and optimize, # another word for optimize is also called move the next step/going to next best position\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        acc += loss*len(inputData)\n",
    "    acc = acc/numTraining\n",
    "    #print(acc)\n",
    "    # After go through entire training set, now we can use the knowledge we learning, to practice with the test set\n",
    "    for i, (inputData, outputData) in enumerate(val_loader):\n",
    "        outputData = outputData.unsqueeze(1)\n",
    "        model.eval()\n",
    "        inputData = inputData.to(device)\n",
    "        outputData = outputData.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(inputData)\n",
    "        #print(outputData.shape)\n",
    "        val_loss = criterion(outputs, outputData)  # this validation loss is already the MSE loss for every sample points\n",
    "        valid_acc += val_loss*len(inputData)\n",
    "    valid_acc = valid_acc/numTest\n",
    "        #mseList.append(val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a28c442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 15])\n"
     ]
    }
   ],
   "source": [
    "for i, (inputData, outputData) in enumerate(train_loader):\n",
    "    print(inputData.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66d0e70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}